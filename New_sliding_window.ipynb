{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "from skimage import color\n",
    "from skimage.feature import hog\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (500, 600)\n",
    "PYR_SCALE = 1.5\n",
    "WIN_STEP = 8\n",
    "ROI_SIZE = (30, 55)\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pyramid(image, scale=1.5, minSize=(224, 224)):\n",
    "\t# yield the original image\n",
    "\tyield image\n",
    "\n",
    "\t# keep looping over the image pyramid\n",
    "\twhile True:\n",
    "\t\t# compute the dimensions of the next image in the pyramid\n",
    "\t\tw = int(image.shape[1] / scale)\n",
    "\t\timage = imutils.resize(image, width=w)\n",
    "\n",
    "\t\t# if the resized image does not meet the supplied minimum\n",
    "\t\t# size, then stop constructing the pyramid\n",
    "\t\tif image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\t# yield the next image in the pyramid\n",
    "\t\tyield image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, step, ws):\n",
    "\t# slide a window across the image\n",
    "\tfor y in range(0, image.shape[0] - ws[1], step):\n",
    "\t\tfor x in range(0, image.shape[1] - ws[0], step):\n",
    "\t\t\t# yield the current window\n",
    "\t\t\tyield (x, y, image[y:y + ws[1], x:x + ws[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_batch(model, batchROIs, batchLocs, labels,scaler, minProb=0.5,\n",
    "    top=10, dims=(30, 55)):\n",
    "    # pass our batch ROIs through our network and decode the\n",
    "    # predictions\n",
    "    batchROIs=scaler.transform(batchROIs)\n",
    "    preds = model.predict(batchROIs)\n",
    "#     P = imagenet_utils.decode_predictions(preds, top=top)\n",
    "    # loop over the decoded predictions\n",
    "    for i in range(0, preds.shape[0]):\n",
    "            # filter out weak detections by ensuring the\n",
    "            # predicted probability is greater than the minimum\n",
    "            # probability\n",
    "        if preds[i] > minProb:\n",
    "                # grab the coordinates of the sliding window for\n",
    "                # the prediction and construct the bounding box\n",
    "            (pX, pY) = batchLocs[i]\n",
    "            box = (pX, pY, pX + dims[0], pY + dims[1])\n",
    "\n",
    "                # grab the list of predictions for the label and\n",
    "                # add the bounding box + probability to the list\n",
    "            L = labels.get(1, [])\n",
    "            L.append((box, preds[i]))\n",
    "            labels[1] = L\n",
    "\n",
    "    # return the labels dictionary\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv2.imread(\"A:\\\\Infilect_project\\\\Product_detector\\\\Dataset\\\\ShelfImages\\\\train\\\\C1_P09_N2_S6_1.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(h, w) = resized.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2151, 3264, 3)\n"
     ]
    }
   ],
   "source": [
    "print(resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv2.resize(resized, INPUT_SIZE, interpolation=cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchROIs = None\n",
    "batchLocs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_input_image(img, img_size):\n",
    "    resized_image = np.resize(img, img_size)\n",
    "    grayscale_image = color.rgb2gray(resized_image)\n",
    "    features = hog(grayscale_image, \n",
    "                   orientations=30, \n",
    "                   pixels_per_cell=(16, 16), \n",
    "                   cells_per_block=(2, 2), \n",
    "                   block_norm='L2-Hys', \n",
    "                   visualize=False, \n",
    "                   transform_sqrt=False, \n",
    "                   feature_vector=True, \n",
    "                   multichannel=None)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaler = pickle.load( open( \"scalers//hog_product_scaler.pkl\", \"rb\" ) )\n",
    "product_classifier = load_model(\"models//hog_product_model.h5\")\n",
    "# for image in image_pyramid(resized, scale=PYR_SCALE,\n",
    "#     minSize=ROI_SIZE):\n",
    "for (x, y, roi) in sliding_window(resized, WIN_STEP, ROI_SIZE):\n",
    "        # take the ROI and pre-process it so we can later classify the\n",
    "        # region with Keras\n",
    "    roi = img_to_array(roi)\n",
    "    # \troi = np.expand_dims(roi, axis=0)\n",
    "    roi = preprocessing_input_image(roi, (128, 128))\n",
    "\n",
    "        # if the batch is None, initialize it\n",
    "    if batchROIs is None:\n",
    "        batchROIs = roi\n",
    "\n",
    "        # otherwise, add the ROI to the bottom of the batch\n",
    "    else:\n",
    "        batchROIs = np.vstack([batchROIs, roi])\n",
    "\n",
    "        # add the (x, y)-coordinates of the sliding window to the batch\n",
    "    batchLocs.append((x, y))\n",
    "\n",
    "        # check to see if our batch is full\n",
    "    if len(batchROIs) == BATCH_SIZE:\n",
    "        # classify the batch, then reset the batch ROIs and\n",
    "        # (x, y)-coordinates\n",
    "        labels = classify_batch(product_classifier, batchROIs, batchLocs,\n",
    "                labels, train_scaler,minProb=0.8)\n",
    "\n",
    "            # reset the batch ROIs and (x, y)-coordinates\n",
    "        batchROIs = None\n",
    "        batchLocs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if batchROIs is not None:\n",
    "\tlabels = classify_batch(product_classifier, batchROIs, batchLocs,\n",
    "\t\t\tlabels, train_scaler,minProb=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 1: 1\n"
     ]
    }
   ],
   "source": [
    "# loop over the labels for each of detected objects in the image\n",
    "for k in labels.keys():\n",
    "  # clone the input image so we can draw on it\n",
    "\tclone = resized.copy()\n",
    "\n",
    "\t# loop over all bounding boxes for the label and draw them on\n",
    "\t# the image\n",
    "\tfor (box, prob) in labels[k]:\n",
    "\t\t(xA, yA, xB, yB) = box\n",
    "\t\tcv2.rectangle(clone, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "\n",
    "\t# show the image *without* apply non-maxima suppression\n",
    "\tcv2.imshow(\"Without NMS\", clone)\n",
    "\tclone = resized.copy()\n",
    "\n",
    "\t# grab the bounding boxes and associated probabilities for each\n",
    "\t# detection, then apply non-maxima suppression to suppress\n",
    "\t# weaker, overlapping detections\n",
    "\tboxes = np.array([p[0] for p in labels[k]])\n",
    "\tproba = np.array([p[1] for p in labels[k]])\n",
    "#     print(proba)\n",
    "\tboxes = non_max_suppression(boxes, proba, overlapThresh=0.9)\n",
    "\n",
    "\t# loop over the bounding boxes again, this time only drawing the\n",
    "\t# ones that were *not* suppressed\n",
    "\tfor (xA, yA, xB, yB) in boxes:\n",
    "\t\tcv2.rectangle(clone, (xA, yA), (xB, yB), (0, 0, 255), 2)\n",
    "\n",
    "\t# show the output image\n",
    "\tprint(\"[INFO] {}: {}\".format(k, len(boxes)))\n",
    "\tcv2.imshow(\"With NMS\", clone)\n",
    "\tcv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
