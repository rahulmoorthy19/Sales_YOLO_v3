{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import PIL\n",
    "from PIL import Image  \n",
    "from skimage import color\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_image(img_path,image_size):\n",
    "    original = Image.open(img_path)  \n",
    "    resized_image = original.resize(image_size)\n",
    "    resized_image.load()\n",
    "    data = np.asarray( resized_image, dtype=\"int32\" )\n",
    "    grayscale_image = color.rgb2gray(data)\n",
    "    features = hog(grayscale_image, \n",
    "                   orientations=30, \n",
    "                   pixels_per_cell=(16, 16), \n",
    "                   cells_per_block=(2, 2), \n",
    "                   block_norm='L2-Hys', \n",
    "                   visualize=False, \n",
    "                   transform_sqrt=False, \n",
    "                   feature_vector=True, \n",
    "                   multichannel=None)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(img_dir,resize_image):\n",
    "    image_data = []\n",
    "    img_label = []\n",
    "    label_counter=0\n",
    "    for each_dir in sorted(glob.glob(img_dir+\"\\\\\"+\"*\"+\"\\\\\")):\n",
    "        for each in sorted(glob.glob(each_dir+\"*.JPG\")):\n",
    "            preprocessed_image = preprocessing_image(each,resize_image)\n",
    "            image_data.append(preprocessed_image)\n",
    "            img_label.append(int(os.path.basename(os.path.dirname(each))))\n",
    "        for each in sorted(glob.glob(each_dir+\"*.PNG\")):\n",
    "            preprocessed_image = preprocessing_image(each,resize_image)\n",
    "            image_data.append(preprocessed_image)\n",
    "            img_label.append(int(os.path.basename(os.path.dirname(each))))\n",
    "    return np.array(image_data), np.array(img_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_divider(dir_label, img_dir, train_obj_dir, test_obj_dir, train_dir, test_dir):\n",
    "    train_data = [os.path.basename(i).split(\".\")[0] for i in glob.glob(train_obj_dir+\"*.JPG\")]\n",
    "    test_data = [os.path.basename(i).split(\".\")[0] for i in glob.glob(test_obj_dir+\"*.JPG\")]\n",
    "    for each in glob.glob(img_dir+\"*.PNG\"):\n",
    "        file_basename = os.path.basename(each).split(\".\")[0]\n",
    "        if file_basename in train_data:\n",
    "            try:\n",
    "                os.mkdir(train_dir + \"\\\\\" + dir_label) \n",
    "            except FileExistsError:\n",
    "                pass\n",
    "            shutil.copy2(each,train_dir + \"\\\\\" + dir_label)\n",
    "        elif file_basename in test_data:\n",
    "            try:\n",
    "                os.mkdir(test_dir + \"\\\\\" + dir_label) \n",
    "            except FileExistsError:\n",
    "                pass\n",
    "            shutil.copy2(each,test_dir + \"\\\\\" + dir_label)\n",
    "    print(\"Train Test Split Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(src_dir, target_dir):\n",
    "    src_dir = glob.glob(src_dir+\"*\"+\"\\\\\")\n",
    "    for i in src_dir:\n",
    "        for each in glob.glob(i+\"*.JPG\"):\n",
    "            shutil.copy2(each,target_dir + \"\\\\\"+ os.path.basename(os.path.dirname(each)))\n",
    "    print(\"Copying Files complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation_pipeline():\n",
    "    with open('config.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "    all_label_dir = glob.glob(data[\"object_classifier_directory\"][\"brand_img_dir\"]+\"\\\\\"+\"*\"+\"\\\\\")\n",
    "    try:\n",
    "        os.mkdir(data[\"object_classifier_directory\"][\"train_brand_dir\"])\n",
    "        os.mkdir(data[\"object_classifier_directory\"][\"test_brand_dir\"])\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    for each in all_label_dir:\n",
    "        train_test_divider(os.path.basename(os.path.dirname(each)), \n",
    "                           each,\n",
    "                           data[\"object_detector_directory\"][\"train_object_dir\"],\n",
    "                           data[\"object_detector_directory\"][\"test_object_dir\"],\n",
    "                           data[\"object_classifier_directory\"][\"train_brand_dir\"],\n",
    "                           data[\"object_classifier_directory\"][\"test_brand_dir\"],\n",
    "                           )\n",
    "    copy_files(data[\"object_classifier_directory\"][\"brand_dir\"], data[\"object_classifier_directory\"][\"train_brand_dir\"])\n",
    "    full_product_data, full_product_label = data_generation(data[\"object_classifier_directory\"][\"train_brand_dir\"],(128,128))\n",
    "    test_product_data, test_product_label = data_generation(data[\"object_classifier_directory\"][\"test_brand_dir\"], (128,128))\n",
    "    os.mkdir(\"features\")\n",
    "    os.mkdir(\"scalers\")\n",
    "    os.mkdir(\"models\")\n",
    "    np.save(\"features\\\\hog_brand_train_array.npy\",full_product_data)\n",
    "    np.save(\"features\\\\hog_brand_test_array.npy\",test_product_data)\n",
    "    np.save(\"features\\\\hog_brand_train_label\", full_product_label)\n",
    "    np.save(\"features\\\\hog_brand_test_label\", test_product_label)\n",
    "    print(\"Final Feature Arrays for Classification Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Feature Arrays for Classification Created\n"
     ]
    }
   ],
   "source": [
    "data_preparation_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
