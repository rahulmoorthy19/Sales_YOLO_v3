{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import PIL\n",
    "from PIL import Image  \n",
    "from skimage import color\n",
    "import shutil\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_image(img_path,image_size):\n",
    "    original = Image.open(img_path)  \n",
    "    resized_image = original.resize(image_size)\n",
    "    resized_image.load()\n",
    "    data = np.asarray( resized_image, dtype=\"int32\" )\n",
    "    grayscale_image = color.rgb2gray(data)  \n",
    "    return grayscale_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(img_dir,resize_image):\n",
    "    print(resize_image)\n",
    "    image_data = []\n",
    "    img_label = []\n",
    "    label_counter=0\n",
    "    for each_dir in sorted(glob.glob(img_dir+\"\\\\\"+\"*\"+\"\\\\\")):\n",
    "        for each in sorted(glob.glob(each_dir+\"*.PNG\")):\n",
    "            preprocessed_image = preprocessing_image(each,resize_image)\n",
    "            image_data.append(preprocessed_image)\n",
    "            img_label.append(int(os.path.basename(os.path.dirname(each))))\n",
    "    return np.array(image_data), np.array(img_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_divider(dir_label, img_dir, train_obj_dir, test_obj_dir, train_dir, test_dir):\n",
    "    train_data = [os.path.basename(i).split(\".\")[0] for i in glob.glob(train_obj_dir+\"*.JPG\")]\n",
    "    test_data = [os.path.basename(i).split(\".\")[0] for i in glob.glob(test_obj_dir+\"*.JPG\")]\n",
    "    for each in glob.glob(img_dir+\"*.PNG\"):\n",
    "        file_basename = os.path.basename(each).split(\".\")[0]\n",
    "        if file_basename in train_data:\n",
    "            try:\n",
    "                os.mkdir(train_dir + \"\\\\\" + dir_label) \n",
    "            except FileExistsError:\n",
    "                pass\n",
    "            shutil.copy2(each,train_dir + \"\\\\\" + dir_label)\n",
    "        elif file_basename in test_data:\n",
    "            try:\n",
    "                os.mkdir(test_dir + \"\\\\\" + dir_label) \n",
    "            except FileExistsError:\n",
    "                pass\n",
    "            shutil.copy2(each,test_dir + \"\\\\\" + dir_label)\n",
    "    print(\"Train Test Split Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation_pipeline():\n",
    "    with open('config.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "#     all_label_dir = glob.glob(data[\"object_classifier_directory\"][\"img_dir\"]+\"*\"+\"\\\\\")\n",
    "#     try:\n",
    "#         os.mkdir(data[\"object_classifier_directory\"][\"train_img_dir\"])\n",
    "#         os.mkdir(data[\"object_classifier_directory\"][\"test_img_dir\"])\n",
    "#     except FileExistsError:\n",
    "#         pass\n",
    "#     for each in all_label_dir:\n",
    "#         train_test_divider(os.path.basename(os.path.dirname(each)), \n",
    "#                            each,\n",
    "#                            data[\"object_detector_directory\"][\"train_object_dir\"],\n",
    "#                            data[\"object_detector_directory\"][\"test_object_dir\"],\n",
    "#                            data[\"object_classifier_directory\"][\"train_img_dir\"],\n",
    "#                            data[\"object_classifier_directory\"][\"test_img_dir\"],\n",
    "#                            )\n",
    "    train_data, train_label = data_generation(data[\"object_classifier_directory\"][\"train_img_dir\"],(55,27))\n",
    "    test_data, test_label = data_generation(data[\"object_classifier_directory\"][\"test_img_dir\"], (55,27))\n",
    "    np.save(\"train_array.npy\",train_data)\n",
    "    np.save(\"test_array.npy\",test_data)\n",
    "    np.save(\"train_label\", train_label)\n",
    "    np.save(\"test_label\", test_label)\n",
    "    print(train_data.shape)\n",
    "    print(\"Final Image Array for Classification Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 27)\n",
      "(55, 27)\n",
      "(10536, 27, 55)\n",
      "Final Image Array for Classification Created\n"
     ]
    }
   ],
   "source": [
    "data_preparation_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
